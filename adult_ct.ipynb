{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "from utils import utils\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers.tensorboard import TensorBoardLogger\n",
    "\n",
    "import utils.args_parser  as argtools\n",
    "import utils.tools as utools\n",
    "from utils.constants import Cte\n",
    "from models import deepsvdd, adcar, adar\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'data_dir': '../Data', 'batch_size': 1000, 'num_workers': 0, 'num_samples_tr': 9999, 'equations_type': 'linear', 'normalize': 'lik', 'likelihood_names': 'c_d_c_b_d_d_c_c_c_c_d', 'lambda_': 0.05, 'normalize_A': None}\n",
      "{'architecture': 'dgnn', 'estimator': 'elbo', 'h_dim_list_dec': [8, 8, 8, 8], 'h_dim_list_enc': [16, 16], 'z_dim': 4, 'distr_z': 'normal', 'dropout_adj_rate': 0.0, 'dropout_adj_pa_rate': 0.2, 'dropout_adj_pa_prob_keep_self': 0.0, 'residual': 1.0, 'norm_categorical': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type        | Params\n",
      "--------------------------------------\n",
      "0 | model | HVACAModule | 63.4 K\n",
      "--------------------------------------\n",
      "63.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "63.4 K    Total params\n",
      "0.254     Total estimated model params size (MB)\n",
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HVACAModule(\n",
      "  (_encoder_embeddings): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (encoder_module): DisjointGNN(\n",
      "    (convs): ModuleList(\n",
      "      (0): DisjointGConv()\n",
      "    )\n",
      "    (activs): ModuleList(\n",
      "      (0): Identity()\n",
      "    )\n",
      "    (dropouts): ModuleList(\n",
      "      (0): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (residuals): ModuleList(\n",
      "      (0): DisjointDense(\n",
      "        (weights): Linear(in_features=11, out_features=128, bias=False)\n",
      "        (bias): Linear(in_features=11, out_features=8, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder_module): DisjointGNN(\n",
      "    (convs): ModuleList(\n",
      "      (0): DisjointGConv()\n",
      "      (1): DisjointGConv()\n",
      "      (2): DisjointGConv()\n",
      "      (3): DisjointGConv()\n",
      "    )\n",
      "    (activs): ModuleList(\n",
      "      (0): ReLU()\n",
      "      (1): ReLU()\n",
      "      (2): ReLU()\n",
      "      (3): Identity()\n",
      "    )\n",
      "    (dropouts): ModuleList(\n",
      "      (0): Dropout(p=0.0, inplace=False)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (residuals): ModuleList(\n",
      "      (0): DisjointDense(\n",
      "        (weights): Linear(in_features=11, out_features=32, bias=False)\n",
      "        (bias): Linear(in_features=11, out_features=8, bias=False)\n",
      "      )\n",
      "      (1): DisjointDense(\n",
      "        (weights): Linear(in_features=11, out_features=64, bias=False)\n",
      "        (bias): Linear(in_features=11, out_features=8, bias=False)\n",
      "      )\n",
      "      (2): DisjointDense(\n",
      "        (weights): Linear(in_features=11, out_features=64, bias=False)\n",
      "        (bias): Linear(in_features=11, out_features=8, bias=False)\n",
      "      )\n",
      "      (3): DisjointDense(\n",
      "        (weights): Linear(in_features=11, out_features=64, bias=False)\n",
      "        (bias): Linear(in_features=11, out_features=8, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (likelihood_z): NormalLikelihood()\n",
      "  (prob_model_x): ProbabilisticModelSCM(\n",
      "    (_decoder_embeddings): ModuleList(\n",
      "      (0): Linear(in_features=8, out_features=3, bias=False)\n",
      "      (1): Linear(in_features=8, out_features=1, bias=False)\n",
      "      (2): Linear(in_features=8, out_features=4, bias=False)\n",
      "      (3): Linear(in_features=8, out_features=1, bias=False)\n",
      "      (4): Linear(in_features=8, out_features=1, bias=False)\n",
      "      (5): Linear(in_features=8, out_features=1, bias=False)\n",
      "      (6): Linear(in_features=8, out_features=4, bias=False)\n",
      "      (7): Linear(in_features=8, out_features=3, bias=False)\n",
      "      (8): Linear(in_features=8, out_features=3, bias=False)\n",
      "      (9): Linear(in_features=8, out_features=3, bias=False)\n",
      "      (10): Linear(in_features=8, out_features=1, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (mse): MSELoss()\n",
      ")\n",
      "Save dir: exper_test/adult_9999_linear_lik_c_d_c_b_d_d_c_c_c_c_d_0.05_None/vaca/dgnn_elbo_8_8_8_8_16_16_4_normal_0.0_0.2_0.0_1.0_0/adam/0.005_0.9_0.999_1.2e-06_exp_lr_0.99/0\n",
      "\n",
      "Loading from: \n",
      "exper_test/adult_9999_linear_lik_c_d_c_b_d_d_c_c_c_c_d_0.05_None/vaca/dgnn_elbo_8_8_8_8_16_16_4_normal_0.0_0.2_0.0_1.0_0/adam/0.005_0.9_0.999_1.2e-06_exp_lr_0.99/0/ckpt/checkpoint-epoch=499.ckpt\n",
      "Model parameters: 63432\n",
      "Normal 49304.1484375, Abnormal 60002.208203125, Abnormal upper 77306.7578125\n",
      "Training normal size: 10000\n",
      "Testing normal size: 10000\n",
      "Testing abnormal size: 1000\n",
      "Results for DeepSVDD:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.97619   0.99630   0.98614     10000\n",
      "           1    0.95340   0.75700   0.84392      1000\n",
      "\n",
      "    accuracy                        0.97455     11000\n",
      "   macro avg    0.96480   0.87665   0.91503     11000\n",
      "weighted avg    0.97412   0.97455   0.97321     11000\n",
      "\n",
      "[[9963   37]\n",
      " [ 243  757]]\n",
      "AUC ROC: 0.9510136\n",
      "AUC PR: 0.900374359065938\n",
      "Results for ADAR:\n",
      "Reconstruction error: 1.776519775390625\n",
      "DeepSVDD pred w/o causal: 1.0\n",
      "GT CR w/o causal: 0.6778523489932886\n",
      "Delta x Avg: 22.751081942028524\n",
      "Ab GT Avg w/o causal: 22.628094502598035\n",
      "--------------------\n",
      "DeepSVDD pred w causal: 1.0\n",
      "GT CR w causal: 0.6778523489932886\n",
      "GT x Avg w causal: 25.084090203521598\n",
      "Ab GT Avg w causal: 24.47448749889911\n",
      "--------------------\n",
      "DeepSVDD pred w VACA: 1.0\n",
      "GT CR w VACA: 0.6845637583892618\n",
      "GT x Avg w VACA: 26.445438639701514\n",
      "Ab GT Avg w VACA: 26.88574939718664\n",
      "--------------------------------------------------\n",
      "Results for ADCAR:\n",
      "Reconstruction MSE norm: 0.0021219642367213964\n",
      "Reconstruction MSE orig: 0.3802865743637085\n",
      "Reconstruction SSE norm: 0.007249776273965836\n",
      "Reconstruction SSE orig: 0.09722495079040527\n",
      "6.626817226409912\n",
      "VACA results:\n",
      "DeepSVDD pred: 1.0\n",
      "GT CR: 0.9530201342281879\n",
      "Delta x Avg Real: 22.63658905029297\n",
      "Ab GT Avg Real: 22.573251724243164\n",
      "Delta x Avg Org: 28.591542412653265\n",
      "Ab GT Avg Org: 27.470714843930516\n",
      "--------------------\n",
      "GT results:\n",
      "DeepSVDD pred w causal: 0.8657718120805369\n",
      "GT CR w causal: 0.7583892617449665\n",
      "GT x Avg w causal: 28.380956436440005\n",
      "Ab GT Avg w causal: 28.365512221440692\n",
      "tensor([ 1.0000,  0.0000,  0.0000,  0.0000, -0.6423,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.4933,  0.0000,  0.0000,  0.0000, -0.4486,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,\n",
      "         0.2787,  0.0000,  0.0000,  0.0000], device='cuda:1',\n",
      "       dtype=torch.float64)\n",
      "113\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=__doc__)\n",
    "parser.add_argument('--dataset_file', default='_params/dataset_adult_all.yaml', type=str,\n",
    "                    help='path to configuration file for the dataset')\n",
    "parser.add_argument('--model_file', default='_params/model_vaca_adult.yaml', type=str,\n",
    "                    help='path to configuration file for the dataset')\n",
    "parser.add_argument('--trainer_file', default='_params/trainer.yaml', type=str,\n",
    "                    help='path to configuration file for the training')\n",
    "parser.add_argument('--yaml_file', default='', type=str, help='path to trained model configuration')\n",
    "parser.add_argument('-d', '--dataset_dict', action=argtools.StoreDictKeyPair, metavar=\"KEY1=VAL1,KEY2=VAL2...\",\n",
    "                    help='manually define dataset configurations as string: KEY1=VALUE1+KEY2=VALUE2+...')\n",
    "parser.add_argument('-m', '--model_dict', action=argtools.StoreDictKeyPair, metavar=\"KEY1=VAL1,KEY2=VAL2...\",\n",
    "                    help='manually define model configurations as string: KEY1=VALUE1+KEY2=VALUE2+...')\n",
    "parser.add_argument('-o', '--optim_dict', action=argtools.StoreDictKeyPair, metavar=\"KEY1=VAL1,KEY2=VAL2...\",\n",
    "                    help='manually define optimizer configurations as string: KEY1=VALUE1+KEY2=VALUE2+...')\n",
    "parser.add_argument('-t', '--trainer_dict', action=argtools.StoreDictKeyPair, metavar=\"KEY1=VAL1,KEY2=VAL2...\",\n",
    "                    help='manually define trainer configurations as string: KEY1=VALUE1+KEY2=VALUE2+...')\n",
    "parser.add_argument('-s', '--seed', default=0, type=int, help='set random seed, default: random')\n",
    "parser.add_argument('-r', '--root_dir', default='', type=str, help='directory for storing results')\n",
    "parser.add_argument('--data_dir', default='', type=str, help='data directory')\n",
    "\n",
    "parser.add_argument('-i', '--is_training', default=0, type=int,\n",
    "                    help='run with training (1) or without training (0)')\n",
    "# parser.add_argument('-f', '--eval_fair', default=True, action=\"store_true\",\n",
    "#                     help='run code with counterfactual fairness experiment (only for German dataset), default: False')\n",
    "parser.add_argument('--show_results', default=0, action=\"store_true\",\n",
    "                    help='run with evaluation (1) or without(0), default: 1')\n",
    "\n",
    "parser.add_argument('--plots', default=0, type=int, help='run code with plotting (1) or without (0), default: 0')\n",
    "\n",
    "# DeepSVDD\n",
    "parser.add_argument('--training_size', default=10000, type=int, help='training size')\n",
    "parser.add_argument('--train_deepsvdd', default=0, type=int, help='train (1) or load(0) deepsvdd')\n",
    "\n",
    "parser.add_argument('--max_epoch_deepsvdd', default=1000, type=int, help='max epoch for training deepsvdd')\n",
    "parser.add_argument('--batch_size_deepsvdd', default=1024, type=int, help='batch size for training deepsvdd')\n",
    "parser.add_argument('--out_dim_deepsvdd', default=2048, type=int, help='output dim for deepsvdd')\n",
    "parser.add_argument('--nu_deepsvdd', default=0.005, type=float, help='quantile for deepsvdd')\n",
    "\n",
    "# ADCAR\n",
    "parser.add_argument('--train_ADCAR', default=0, type=int, help='train (1) or load(0) ADCAR')\n",
    "parser.add_argument('--train_ADAR', default=0, type=int, help='train (1) or load(0) ADAR')\n",
    "parser.add_argument('--cost_function', default=1, type=int, help='using cost function')\n",
    "parser.add_argument('--l2_alpha', default=1e-3, type=float, help='Weight for the l2 loss')\n",
    "# parser.add_argument('--l2_alpha', default=1e-4, type=float, help='Weight for the l2 loss')\n",
    "parser.add_argument('--device', default='cuda:1', type=str, help='Device to use')\n",
    "parser.add_argument('--max_epoch_ADCAR', default=20, type=int, help='max epoch for training ADCAR')\n",
    "parser.add_argument('--batch_size_ADCAR', default=128, type=int, help='batch size for training ADCAR')\n",
    "parser.add_argument('--learning_rate_ADCAR', default=1e-5, type=float, help='Learning rate for ADCAR')\n",
    "\n",
    "parser.add_argument('--r_ratio', default=0.9, type=float, help='R ratio for flap samples')\n",
    "\n",
    "\n",
    "args = parser.parse_args('')\n",
    "\n",
    "# %%\n",
    "if args.yaml_file == '':\n",
    "    cfg = argtools.parse_args(args.dataset_file)\n",
    "    cfg.update(argtools.parse_args(args.model_file))\n",
    "    cfg.update(argtools.parse_args(args.trainer_file))\n",
    "else:\n",
    "    cfg = argtools.parse_args(args.yaml_file)\n",
    "if len(args.root_dir) > 0:  cfg['root_dir'] = args.root_dir\n",
    "if int(args.seed) >= 0:\n",
    "    cfg['seed'] = int(args.seed)\n",
    "\n",
    "\n",
    "# %%\n",
    "pl.seed_everything(cfg['seed'])\n",
    "utils.set_seed(cfg['seed'])\n",
    "\n",
    "if args.dataset_dict is not None: cfg['dataset']['params2'].update(args.dataset_dict)\n",
    "if args.model_dict is not None: cfg['model']['params'].update(args.model_dict)\n",
    "if args.optim_dict is not None: cfg['optimizer']['params'].update(args.optim_dict)\n",
    "if args.trainer_dict is not None: cfg['trainer'].update(args.trainer_dict)\n",
    "\n",
    "if isinstance(cfg['trainer']['gpus'], int):\n",
    "    cfg['trainer']['auto_select_gpus'] = False\n",
    "    cfg['trainer']['gpus'] = -1\n",
    "\n",
    "cfg['dataset']['params'] = cfg['dataset']['params1'].copy()\n",
    "cfg['dataset']['params'].update(cfg['dataset']['params2'])\n",
    "\n",
    "if len(args.data_dir) > 0:\n",
    "    cfg['dataset']['params']['data_dir'] = args.data_dir\n",
    "\n",
    "print(args.dataset_dict)\n",
    "print(cfg['dataset']['params'])\n",
    "print(cfg['model']['params'])\n",
    "\n",
    "# %% Load dataset\n",
    "\n",
    "data_module = None\n",
    "\n",
    "if cfg['dataset']['name'] in Cte.DATASET_LIST:\n",
    "    from data_modules.het_scm import HeterogeneousSCMDataModule\n",
    "\n",
    "    dataset_params = cfg['dataset']['params'].copy()\n",
    "    dataset_params['dataset_name'] = cfg['dataset']['name']\n",
    "    dataset_params['num_samples_tr'] = args.training_size\n",
    "\n",
    "    data_module = HeterogeneousSCMDataModule(**dataset_params)\n",
    "\n",
    "    data_module.prepare_data()\n",
    "\n",
    "assert data_module is not None, cfg['dataset']\n",
    "\n",
    "\n",
    "# %% Load model\n",
    "model_vaca = None\n",
    "model_params = cfg['model']['params'].copy()\n",
    "# VACA\n",
    "if cfg['model']['name'] == Cte.VACA:\n",
    "    from models.vaca.vaca import VACA\n",
    "\n",
    "    model_params['is_heterogeneous'] = data_module.is_heterogeneous\n",
    "    model_params['likelihood_x'] = data_module.likelihood_list\n",
    "\n",
    "    model_params['deg'] = data_module.get_deg(indegree=True)\n",
    "    model_params['num_nodes'] = data_module.num_nodes\n",
    "    model_params['edge_dim'] = data_module.edge_dimension\n",
    "    model_params['scaler'] = data_module.scaler\n",
    "\n",
    "    model_vaca = VACA(**model_params)\n",
    "    model_vaca.set_random_train_sampler(data_module.get_random_train_sampler())\n",
    "# VACA with PIWAE\n",
    "elif cfg['model']['name'] == Cte.VACA_PIWAE:\n",
    "    from models.vaca.vaca_piwae import VACA_PIWAE\n",
    "\n",
    "    model_params['is_heterogeneous'] = data_module.is_heterogeneous\n",
    "\n",
    "    model_params['likelihood_x'] = data_module.likelihood_list\n",
    "\n",
    "    model_params['deg'] = data_module.get_deg(indegree=True)\n",
    "    model_params['num_nodes'] = data_module.num_nodes\n",
    "    model_params['edge_dim'] = data_module.edge_dimension\n",
    "    model_params['scaler'] = data_module.scaler\n",
    "\n",
    "    model_vaca = VACA_PIWAE(**model_params)\n",
    "    model_vaca.set_random_train_sampler(data_module.get_random_train_sampler())\n",
    "\n",
    "\n",
    "\n",
    "# MultiCVAE\n",
    "elif cfg['model']['name'] == Cte.MCVAE:\n",
    "    from models.multicvae.multicvae import MCVAE\n",
    "\n",
    "    model_params['likelihood_x'] = data_module.likelihood_list\n",
    "\n",
    "    model_params['topological_node_dims'] = data_module.train_dataset.get_node_columns_in_X()\n",
    "    model_params['topological_parents'] = data_module.topological_parents\n",
    "    model_params['scaler'] = data_module.scaler\n",
    "    model_params['num_epochs_per_nodes'] = int(\n",
    "        np.floor((cfg['trainer']['max_epochs'] / len(data_module.topological_nodes))))\n",
    "    model_vaca = MCVAE(**model_params)\n",
    "    model_vaca.set_random_train_sampler(data_module.get_random_train_sampler())\n",
    "    cfg['early_stopping'] = False\n",
    "\n",
    "# CAREFL\n",
    "elif cfg['model']['name'] == Cte.CARELF:\n",
    "    from models.carefl.carefl import CAREFL\n",
    "\n",
    "    model_params['node_per_dimension_list'] = data_module.train_dataset.node_per_dimension_list\n",
    "    model_params['scaler'] = data_module.scaler\n",
    "    model_vaca = CAREFL(**model_params)\n",
    "assert model_vaca is not None\n",
    "\n",
    "utools.enablePrint()\n",
    "\n",
    "print(model_vaca.model)\n",
    "model_vaca.summarize()\n",
    "model_vaca.set_optim_params(optim_params=cfg['optimizer'],\n",
    "                            sched_params=cfg['scheduler'])\n",
    "\n",
    "# %% Evaluator\n",
    "\n",
    "evaluator = None\n",
    "\n",
    "if cfg['dataset']['name'] in Cte.DATASET_LIST:\n",
    "    from models._evaluator import MyEvaluator\n",
    "\n",
    "    evaluator = MyEvaluator(model=model_vaca,\n",
    "                            intervention_list=data_module.train_dataset.get_intervention_list(),\n",
    "                            scaler=data_module.scaler\n",
    "                            )\n",
    "\n",
    "assert evaluator is not None\n",
    "\n",
    "model_vaca.set_my_evaluator(evaluator=evaluator)\n",
    "\n",
    "# %% Prepare training\n",
    "if args.yaml_file == '':\n",
    "    if (cfg['dataset']['name'] in [Cte.GERMAN]) and (cfg['dataset']['params3']['train_kfold'] == True):\n",
    "        save_dir = argtools.mkdir(os.path.join(cfg['root_dir'],\n",
    "                                               argtools.get_experiment_folder(cfg),\n",
    "                                               str(cfg['seed']), str(cfg['dataset']['params3']['kfold_idx'])))\n",
    "    else:\n",
    "        save_dir = argtools.mkdir(os.path.join(cfg['root_dir'],\n",
    "                                               argtools.get_experiment_folder(cfg),\n",
    "                                               str(cfg['seed'])))\n",
    "else:\n",
    "    save_dir = os.path.join(*args.yaml_file.split('/')[:-1])\n",
    "print(f'Save dir: {save_dir}')\n",
    "# trainer = pl.Trainer(**cfg['model'])\n",
    "logger = TensorBoardLogger(save_dir=save_dir, name='logs', default_hp_metric=False)\n",
    "out = logger.log_hyperparams(argtools.flatten_cfg(cfg))\n",
    "\n",
    "save_dir_ckpt = argtools.mkdir(os.path.join(save_dir, 'ckpt'))\n",
    "ckpt_file = argtools.newest(save_dir_ckpt)\n",
    "callbacks = []\n",
    "if args.is_training == 1:\n",
    "\n",
    "    checkpoint = ModelCheckpoint(period=1,\n",
    "                                 monitor=model_vaca.monitor(),\n",
    "                                 mode=model_vaca.monitor_mode(),\n",
    "                                 save_top_k=1,\n",
    "                                 save_last=True,\n",
    "                                 filename='checkpoint-{epoch:02d}',\n",
    "                                 dirpath=save_dir_ckpt)\n",
    "\n",
    "    callbacks = [checkpoint]\n",
    "\n",
    "    if cfg['early_stopping']:\n",
    "        early_stopping = EarlyStopping(model_vaca.monitor(), mode=model_vaca.monitor_mode(), min_delta=0.0,\n",
    "                                       patience=50)\n",
    "        callbacks.append(early_stopping)\n",
    "\n",
    "    if ckpt_file is not None:\n",
    "        print(f'Loading model training: {ckpt_file}')\n",
    "        trainer = pl.Trainer(logger=logger, callbacks=callbacks, resume_from_checkpoint=ckpt_file,\n",
    "                             **cfg['trainer'])\n",
    "    else:\n",
    "\n",
    "        trainer = pl.Trainer(logger=logger, callbacks=callbacks, **cfg['trainer'])\n",
    "\n",
    "    # %% Train\n",
    "\n",
    "    trainer.fit(model_vaca, data_module)\n",
    "    # save_yaml(model.get_arguments(), file_path=os.path.join(save_dir, 'hparams_model.yaml'))\n",
    "    argtools.save_yaml(cfg, file_path=os.path.join(save_dir, 'hparams_full.yaml'))\n",
    "    # %% Testing\n",
    "\n",
    "else:\n",
    "    # %% Testing\n",
    "    trainer = pl.Trainer()\n",
    "    print('\\nLoading from: ')\n",
    "    print(ckpt_file)\n",
    "\n",
    "    model_vaca = model_vaca.load_from_checkpoint(ckpt_file, **model_params)\n",
    "    evaluator.set_model(model_vaca)\n",
    "    model_vaca.set_my_evaluator(evaluator=evaluator)\n",
    "\n",
    "    if cfg['model']['name'] in [Cte.VACA_PIWAE, Cte.VACA, Cte.MCVAE]:\n",
    "        model_vaca.set_random_train_sampler(data_module.get_random_train_sampler())\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model_vaca.parameters())\n",
    "params = int(sum([np.prod(p.size()) for p in model_parameters]))\n",
    "\n",
    "print(f'Model parameters: {params}')\n",
    "model_vaca.eval()\n",
    "model_vaca.freeze()  # IMPORTANT\n",
    "\n",
    "if args.show_results:\n",
    "    output_valid = model_vaca.evaluate(dataloader=data_module.val_dataloader(),\n",
    "                                       name='valid',\n",
    "                                       save_dir=save_dir,\n",
    "                                       plots=False)\n",
    "    output_test = model_vaca.evaluate(dataloader=data_module.test_dataloader(),\n",
    "                                      name='test',\n",
    "                                      save_dir=save_dir,\n",
    "                                      plots=args.plots)\n",
    "    output_valid.update(output_test)\n",
    "\n",
    "    output_valid.update(argtools.flatten_cfg(cfg))\n",
    "    output_valid.update({'ckpt_file': ckpt_file,\n",
    "                         'num_parameters': params})\n",
    "\n",
    "    with open(os.path.join(save_dir, 'output.json'), 'w') as f:\n",
    "        json.dump(output_valid, f)\n",
    "    print(f'Experiment folder: {save_dir}')\n",
    "    \n",
    "dataset_params['num_samples_tr'] = args.training_size * 10\n",
    "data_module = HeterogeneousSCMDataModule(**dataset_params)\n",
    "data_module.prepare_data()\n",
    "\n",
    "thres_n, thres_ab, df_train, df_valid, df_test = utils.split_dataset(data_module, name=cfg['dataset']['name'], \\\n",
    "                                                                     training_size=args.training_size,\n",
    "                                                                     seed=args.seed)      \n",
    "\n",
    "if cfg['dataset']['name'] == 'loan':\n",
    "    input_dim = data_module.train_dataset.X0.shape[-1]\n",
    "elif cfg['dataset']['name'] == 'adult':\n",
    "    input_dim = data_module.train_dataset.X0.shape[-1] - 4\n",
    "elif cfg['dataset']['name'] == 'donors':\n",
    "    input_dim = data_module.train_dataset.X0.shape[-1] - 1\n",
    "else:\n",
    "    NotImplementedError\n",
    "\n",
    "model_deepsvdd = deepsvdd.DeepSVDD(input_dim=input_dim, out_dim=args.out_dim_deepsvdd,\n",
    "                                   batch_size=args.batch_size_deepsvdd, nu=args.nu_deepsvdd,\n",
    "                                   max_epoch=args.max_epoch_deepsvdd, data=data_module.dataset_name,\n",
    "                                   device=args.device)\n",
    "\n",
    "if cfg['dataset']['name'] == 'loan':\n",
    "    train_X = data_module.scaler.transform(data_module.train_dataset.X0)\n",
    "    valid_X = data_module.scaler.transform(data_module.valid_dataset.X0)\n",
    "    test_X = data_module.scaler.transform(data_module.test_dataset.X0)\n",
    "elif cfg['dataset']['name'] == 'adult':\n",
    "    train_X = data_module.scaler.transform(data_module.train_dataset.X0)[:, :-4]\n",
    "    valid_X = data_module.scaler.transform(data_module.valid_dataset.X0)[:, :-4]\n",
    "    test_X = data_module.scaler.transform(data_module.test_dataset.X0)[:, :-4]\n",
    "elif cfg['dataset']['name'] == 'donors':\n",
    "    train_X = data_module.scaler.transform(data_module.train_dataset.X0)[:, :-1]\n",
    "    valid_X = data_module.scaler.transform(data_module.valid_dataset.X0)[:, :-1]\n",
    "    test_X = data_module.scaler.transform(data_module.test_dataset.X0)[:, :-1]\n",
    "else:\n",
    "    NotImplementedError\n",
    "\n",
    "if args.train_deepsvdd:\n",
    "    print('Training DeepSVDD:')\n",
    "    model_deepsvdd.train_DeepSVDD(train_X, valid_X)\n",
    "\n",
    "print('Results for DeepSVDD:')\n",
    "model_deepsvdd.load_model()\n",
    "model_deepsvdd.get_R(train_X)\n",
    "if cfg['dataset']['name'] == 'donors':\n",
    "    lst_dist, lst_pred = model_deepsvdd.predict(test_X, label=df_test['is_exciting'].values, result=1)\n",
    "else:\n",
    "    lst_dist, lst_pred = model_deepsvdd.predict(test_X, label=df_test['label'].values, result=1)\n",
    "\n",
    "if cfg['dataset']['name'] == 'loan':\n",
    "    out_dim = 6\n",
    "elif cfg['dataset']['name'] == 'adult':\n",
    "    out_dim = 3\n",
    "elif cfg['dataset']['name'] == 'donors':\n",
    "    out_dim = 3\n",
    "else:\n",
    "    NotImplementedError\n",
    "\n",
    "\n",
    "model_adar = adar.ADAR(input_dim, out_dim, model_deepsvdd, model_vaca, data_module,\n",
    "                       alpha=args.l2_alpha, batch_size=args.batch_size_ADCAR, max_epoch=args.max_epoch_ADCAR,\n",
    "                       device=args.device, data=cfg['dataset']['name'], cost_f=args.cost_function,\n",
    "                       R_ratio=args.r_ratio, lr=args.learning_rate_ADCAR)\n",
    "#                        device=args.device, data=cfg['dataset']['name'], cost_f=args.cost_function, R_ratio=i)\n",
    "x_train, u_train, x_valid, u_valid, x_test, u_test, df = utils.prepare_adcar_training_data(df_test, lst_pred, data_module,\n",
    "                                                                                           cfg['dataset']['name'])\n",
    "if args.train_ADAR:\n",
    "    print('Training ADAR:')\n",
    "    model_adar.train_ADAR(x_train, u_train, x_valid, u_valid)\n",
    "print('Results for ADAR:')\n",
    "# model_adar.predict(x_train, u_train)\n",
    "model_adar.predict(x_test, u_test, thres_n=thres_n)\n",
    "\n",
    "print('-'*50)\n",
    "model_adcar = adcar.ADCAR(input_dim, out_dim, model_deepsvdd, model_vaca, data_module,\n",
    "                       alpha=args.l2_alpha, batch_size=args.batch_size_ADCAR, max_epoch=args.max_epoch_ADCAR,\n",
    "                       device=args.device, data=cfg['dataset']['name'], cost_f=args.cost_function, \n",
    "                          R_ratio = args.r_ratio, lr = args.learning_rate_ADCAR)\n",
    "\n",
    "if args.train_ADCAR:\n",
    "    print('Training ADCAR:')\n",
    "    model_adcar.train_ADCAR(x_train, u_train, x_valid, u_valid)\n",
    "print('Results for ADCAR:')\n",
    "# model_adcar.predict(x_train, u_train)\n",
    "model_adcar.predict(x_test, u_test, thres_n=thres_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "index = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_0</th>\n",
       "      <th>R_1</th>\n",
       "      <th>R_2</th>\n",
       "      <th>A</th>\n",
       "      <th>N_0</th>\n",
       "      <th>N_1</th>\n",
       "      <th>N_2</th>\n",
       "      <th>N_3</th>\n",
       "      <th>S</th>\n",
       "      <th>E</th>\n",
       "      <th>...</th>\n",
       "      <th>M_0</th>\n",
       "      <th>M_1</th>\n",
       "      <th>M_2</th>\n",
       "      <th>O_0</th>\n",
       "      <th>O_1</th>\n",
       "      <th>O_2</th>\n",
       "      <th>L_0</th>\n",
       "      <th>L_1</th>\n",
       "      <th>L_2</th>\n",
       "      <th>I</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.229317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.708817</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.740051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.022753</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.740051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.567446</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42816.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   R_0  R_1  R_2          A  N_0  N_1  N_2  N_3    S          E  ...  M_0  \\\n",
       "0  1.0  0.0  0.0  38.229317  0.0  0.0  0.0  1.0  1.0  21.708817  ...  1.0   \n",
       "1  1.0  0.0  0.0  33.740051  0.0  0.0  0.0  1.0  1.0   1.022753  ...  1.0   \n",
       "2  1.0  0.0  0.0  33.740051  0.0  0.0  0.0  1.0  1.0   0.567446  ...  1.0   \n",
       "\n",
       "   M_1  M_2  O_0  O_1  O_2  L_0  L_1  L_2        I  \n",
       "0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  52304.0  \n",
       "1  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  42816.0  \n",
       "2  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  42816.0  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_theta_adar, _,_, df_adar = model_adar.get_result(x_test[index], u_test[index])\n",
    "x_theta_adcar, _,_, df_adcar = model_adcar.get_result(x_test[index], u_test[index])\n",
    "index += 1\n",
    "df_adar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>E</th>\n",
       "      <th>H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38.229317</td>\n",
       "      <td>21.708817</td>\n",
       "      <td>19.243423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.740051</td>\n",
       "      <td>1.022753</td>\n",
       "      <td>22.527348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.740051</td>\n",
       "      <td>0.567446</td>\n",
       "      <td>21.988293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           A          E          H\n",
       "0  38.229317  21.708817  19.243423\n",
       "1  33.740051   1.022753  22.527348\n",
       "2  33.740051   0.567446  21.988293"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adar[['A', 'E', 'H']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -4.4892645, -20.686064 ,   3.283924 ], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_theta_adar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_0</th>\n",
       "      <th>R_1</th>\n",
       "      <th>R_2</th>\n",
       "      <th>A</th>\n",
       "      <th>N_0</th>\n",
       "      <th>N_1</th>\n",
       "      <th>N_2</th>\n",
       "      <th>N_3</th>\n",
       "      <th>S</th>\n",
       "      <th>E</th>\n",
       "      <th>...</th>\n",
       "      <th>M_0</th>\n",
       "      <th>M_1</th>\n",
       "      <th>M_2</th>\n",
       "      <th>O_0</th>\n",
       "      <th>O_1</th>\n",
       "      <th>O_2</th>\n",
       "      <th>L_0</th>\n",
       "      <th>L_1</th>\n",
       "      <th>L_2</th>\n",
       "      <th>I</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.229317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.708817</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.163723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.319626</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.916876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.651049</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   R_0  R_1  R_2          A  N_0  N_1  N_2  N_3    S          E  ...  M_0  \\\n",
       "0  1.0  0.0  0.0  38.229317  0.0  0.0  0.0  1.0  1.0  21.708817  ...  1.0   \n",
       "1  1.0  0.0  0.0  30.163723  0.0  0.0  0.0  1.0  1.0   7.319626  ...  1.0   \n",
       "2  1.0  0.0  0.0  21.916876  0.0  0.0  0.0  1.0  1.0  -4.651049  ...  1.0   \n",
       "\n",
       "   M_1  M_2  O_0  O_1  O_2  L_0  L_1  L_2        I  \n",
       "0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  52304.0  \n",
       "1  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  42816.0  \n",
       "2  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  40000.0  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adcar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>E</th>\n",
       "      <th>H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62.222588</td>\n",
       "      <td>22.202030</td>\n",
       "      <td>25.532274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.974012</td>\n",
       "      <td>8.239930</td>\n",
       "      <td>27.466457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.305290</td>\n",
       "      <td>9.213397</td>\n",
       "      <td>29.291668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           A          E          H\n",
       "0  62.222588  22.202030  25.532274\n",
       "1  28.974012   8.239930  27.466457\n",
       "2  44.305290   9.213397  29.291668"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adcar[['A', 'E', 'H']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-18.395948 , -12.31012  ,   3.6144445], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_theta_adcar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "x_org = []\n",
    "x_pred = []\n",
    "x_gt = []\n",
    "for i in range(len(x_test)):\n",
    "    _, _, _, df = model_adcar.get_result(x_test[i], u_test[i])\n",
    "    if df.iloc[1,-1] < 50000 and df.iloc[2,-1] < 50000:\n",
    "        x_org.append(df.iloc[0, :].values)\n",
    "        x_pred.append(df.iloc[1, :].values)\n",
    "        x_gt.append(df.iloc[2, :].values)\n",
    "x_org = torch.tensor(data_module.train_dataset.fill_up_with_zeros(data_module.scaler.transform(x_org))[0]).to(args.device)\n",
    "x_pred = torch.tensor(data_module.train_dataset.fill_up_with_zeros(data_module.scaler.transform(x_pred))[0]).to(args.device)\n",
    "x_gt = torch.tensor(data_module.train_dataset.fill_up_with_zeros(data_module.scaler.transform(x_gt))[0]).to(args.device)\n",
    "print(x_org[0])\n",
    "x_org_res = model_deepsvdd.net.forward(x_org[:,:-4].float()).data.cpu().numpy()\n",
    "x_pred_res = model_deepsvdd.net.forward(x_pred[:,:-4].float()).data.cpu().numpy()\n",
    "x_norm_res = model_deepsvdd.net.forward(train_X[:len(x_org_res)].to(args.device)).data.cpu().numpy()\n",
    "x_gt_res = model_deepsvdd.net.forward(x_gt.float()).data.cpu().numpy()\n",
    "center = model_deepsvdd.c.numpy()\n",
    "print(len(x_org))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "state =0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "state = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'manifold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [13]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28mall\u001B[39m \u001B[38;5;241m=\u001B[39m x_pred_res \u001B[38;5;241m+\u001B[39m [center]\n\u001B[0;32m----> 4\u001B[0m tsne \u001B[38;5;241m=\u001B[39m \u001B[43mmanifold\u001B[49m\u001B[38;5;241m.\u001B[39mTSNE(n_components\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, init\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrandom\u001B[39m\u001B[38;5;124m'\u001B[39m, perplexity\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m80\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m21\u001B[39m, n_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5000\u001B[39m, \n\u001B[1;32m      5\u001B[0m                      n_iter_without_progress\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# tsne = manifold.MDS(n_components=2, random_state=state)\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# tsne = manifold.Isomap(n_components=2)\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# tsne = manifold.LocallyLinearEmbedding(n_components=2, eigen_solver='dense', random_state=state)\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# tsne = manifold.SpectralEmbedding(n_components=2, affinity='rbf')\u001B[39;00m\n\u001B[1;32m     11\u001B[0m tsne_all \u001B[38;5;241m=\u001B[39m tsne\u001B[38;5;241m.\u001B[39mfit_transform(\u001B[38;5;28mall\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'manifold' is not defined"
     ]
    }
   ],
   "source": [
    "all = x_pred_res + [center]\n",
    "\n",
    "\n",
    "tsne = manifold.TSNE(n_components=2, init='random', perplexity=80, random_state=21, n_iter=5000, \n",
    "                     n_iter_without_progress=100, learning_rate=100)\n",
    "# tsne = manifold.MDS(n_components=2, random_state=state)\n",
    "# tsne = manifold.Isomap(n_components=2)\n",
    "# tsne = manifold.LocallyLinearEmbedding(n_components=2, eigen_solver='dense', random_state=state)\n",
    "# tsne = manifold.SpectralEmbedding(n_components=2, affinity='rbf')\n",
    "\n",
    "tsne_all = tsne.fit_transform(all)\n",
    "tsne_org = tsne.fit_transform(x_org_res)\n",
    "tsne_norm = tsne.fit_transform(x_norm_res)\n",
    "tsne_gt = tsne.fit_transform(x_gt_res)\n",
    "# tsne_normal_t = tsne.fit_transform(X_normal_t)\n",
    "# tsne_abnormal_t = tsne.fit_transform(X_abnormal_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "plt.scatter(tsne_org[:,0],tsne_org[:,1], marker='o', s=10, alpha = 1.0,label = 'Abnormal samples')\n",
    "plt.scatter(tsne_norm[:,0],tsne_norm[:,1], marker='o', s=10, alpha = 1.0,label = 'Normal samples')\n",
    "plt.scatter(tsne_all[:-1,0],tsne_all[:-1,1], marker='o', s=10, alpha = 1.0 ,label = 'ADCAR counterfactual samples')\n",
    "plt.scatter(tsne_gt[:,0],tsne_gt[:,1],  marker='o', s=10, alpha = 1.0 ,label = 'Counterfactual samples')\n",
    "plt.scatter(tsne_all[-1,0],tsne_all[-1,1], color = 'black',marker='*', s=300, alpha = 1.0,label = 'Center')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "ax = plt.gca()\n",
    "ax.axes.xaxis.set_ticks([])\n",
    "ax.axes.yaxis.set_ticks([])\n",
    "ax.axes.xaxis.set_ticklabels([])\n",
    "ax.axes.yaxis.set_ticklabels([])\n",
    "# plt.show()\n",
    "state+= 1\n",
    "plt.savefig('Adult_tsne_3.png', dpi=300, bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}