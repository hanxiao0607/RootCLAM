{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "from utils import utils\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers.tensorboard import TensorBoardLogger\n",
    "\n",
    "import utils.args_parser  as argtools\n",
    "import utils.tools as utools\n",
    "from utils.constants import Cte\n",
    "from models import deepsvdd, adcar, adar\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'data_dir': '../Data', 'batch_size': 1000, 'num_workers': 0, 'num_samples_tr': 9999, 'equations_type': 'linear', 'normalize': 'lik', 'likelihood_names': 'b_b_b_b_b_b_b_d_d_d', 'lambda_': 0.05, 'normalize_A': None}\n",
      "{'architecture': 'dgnn', 'estimator': 'elbo', 'h_dim_list_dec': [8, 8, 8, 8], 'h_dim_list_enc': [16, 16], 'z_dim': 4, 'distr_z': 'normal', 'dropout_adj_rate': 0.0, 'dropout_adj_pa_rate': 0.2, 'dropout_adj_pa_prob_keep_self': 0.0, 'residual': 1.0, 'norm_categorical': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type        | Params\n",
      "--------------------------------------\n",
      "0 | model | HVACAModule | 42.5 K\n",
      "--------------------------------------\n",
      "42.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "42.5 K    Total params\n",
      "0.170     Total estimated model params size (MB)\n",
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HVACAModule(\n",
      "  (_encoder_embeddings): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (encoder_module): DisjointGNN(\n",
      "    (convs): ModuleList(\n",
      "      (0): DisjointGConv()\n",
      "    )\n",
      "    (activs): ModuleList(\n",
      "      (0): Identity()\n",
      "    )\n",
      "    (dropouts): ModuleList(\n",
      "      (0): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (residuals): ModuleList(\n",
      "      (0): DisjointDense(\n",
      "        (weights): Linear(in_features=11, out_features=128, bias=False)\n",
      "        (bias): Linear(in_features=11, out_features=8, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder_module): DisjointGNN(\n",
      "    (convs): ModuleList(\n",
      "      (0): DisjointGConv()\n",
      "      (1): DisjointGConv()\n",
      "      (2): DisjointGConv()\n",
      "      (3): DisjointGConv()\n",
      "    )\n",
      "    (activs): ModuleList(\n",
      "      (0): ReLU()\n",
      "      (1): ReLU()\n",
      "      (2): ReLU()\n",
      "      (3): Identity()\n",
      "    )\n",
      "    (dropouts): ModuleList(\n",
      "      (0): Dropout(p=0.0, inplace=False)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (residuals): ModuleList(\n",
      "      (0): DisjointDense(\n",
      "        (weights): Linear(in_features=11, out_features=32, bias=False)\n",
      "        (bias): Linear(in_features=11, out_features=8, bias=False)\n",
      "      )\n",
      "      (1): DisjointDense(\n",
      "        (weights): Linear(in_features=11, out_features=64, bias=False)\n",
      "        (bias): Linear(in_features=11, out_features=8, bias=False)\n",
      "      )\n",
      "      (2): DisjointDense(\n",
      "        (weights): Linear(in_features=11, out_features=64, bias=False)\n",
      "        (bias): Linear(in_features=11, out_features=8, bias=False)\n",
      "      )\n",
      "      (3): DisjointDense(\n",
      "        (weights): Linear(in_features=11, out_features=64, bias=False)\n",
      "        (bias): Linear(in_features=11, out_features=8, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (likelihood_z): NormalLikelihood()\n",
      "  (prob_model_x): ProbabilisticModelSCM(\n",
      "    (_decoder_embeddings): ModuleList(\n",
      "      (0): Linear(in_features=8, out_features=1, bias=False)\n",
      "      (1): Linear(in_features=8, out_features=1, bias=False)\n",
      "      (2): Linear(in_features=8, out_features=1, bias=False)\n",
      "      (3): Linear(in_features=8, out_features=1, bias=False)\n",
      "      (4): Linear(in_features=8, out_features=1, bias=False)\n",
      "      (5): Linear(in_features=8, out_features=1, bias=False)\n",
      "      (6): Linear(in_features=8, out_features=1, bias=False)\n",
      "      (7): Linear(in_features=8, out_features=1, bias=False)\n",
      "      (8): Linear(in_features=8, out_features=1, bias=False)\n",
      "      (9): Linear(in_features=8, out_features=1, bias=False)\n",
      "      (10): Linear(in_features=8, out_features=1, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (mse): MSELoss()\n",
      ")\n",
      "Save dir: exper_test/donors_9999_linear_lik_b_b_b_b_b_b_b_d_d_d_0.05_None/vaca/dgnn_elbo_8_8_8_8_16_16_4_normal_0.0_0.2_0.0_1.0_0/adam/0.005_0.9_0.999_1.2e-06_exp_lr_0.99/0\n",
      "\n",
      "Loading from: \n",
      "exper_test/donors_9999_linear_lik_b_b_b_b_b_b_b_d_d_d_0.05_None/vaca/dgnn_elbo_8_8_8_8_16_16_4_normal_0.0_0.2_0.0_1.0_0/adam/0.005_0.9_0.999_1.2e-06_exp_lr_0.99/0/ckpt/checkpoint-epoch=497.ckpt\n",
      "Model parameters: 42504\n",
      "Results for DeepSVDD:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    0.99948   0.99809   0.99878     26710\n",
      "         1.0    0.98117   0.99476   0.98792      2671\n",
      "\n",
      "    accuracy                        0.99779     29381\n",
      "   macro avg    0.99032   0.99642   0.99335     29381\n",
      "weighted avg    0.99781   0.99779   0.99779     29381\n",
      "\n",
      "[[26659    51]\n",
      " [   14  2657]]\n",
      "AUC ROC: 0.9993011520076207\n",
      "AUC PR: 0.9974793959994017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ADAR:\n",
      "Epoch loss: 0.8520792424678802, epoch dist loss: 0.8448224663734436, epoch l2 loss: 725.677831619978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|██▏                                         | 1/20 [00:06<02:09,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 0.8523390889167786, epoch dist loss: 0.8426611870527267, epoch l2 loss: 967.7907295227051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████▍                                       | 2/20 [00:13<02:02,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 0.8569421581923962, epoch dist loss: 0.8468168377876282, epoch l2 loss: 1012.5320701599121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|██████▌                                     | 3/20 [00:20<01:55,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 0.856270145624876, epoch dist loss: 0.8458615131676197, epoch l2 loss: 1040.8624954223633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████▊                                   | 4/20 [00:27<01:48,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 0.8505942262709141, epoch dist loss: 0.8403522558510303, epoch l2 loss: 1024.1974411010742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|███████████                                 | 5/20 [00:34<01:42,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 0.8574148043990135, epoch dist loss: 0.8469192534685135, epoch l2 loss: 1049.5558013916016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|█████████████▏                              | 6/20 [00:40<01:35,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 0.8511158637702465, epoch dist loss: 0.8407956995069981, epoch l2 loss: 1032.0158233642578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███████████████▍                            | 7/20 [00:47<01:28,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 0.8554016686975956, epoch dist loss: 0.8448303565382957, epoch l2 loss: 1057.130931854248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████▌                          | 8/20 [00:54<01:21,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 0.8539335243403912, epoch dist loss: 0.843481719493866, epoch l2 loss: 1045.1806106567383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|███████████████████▊                        | 9/20 [01:01<01:14,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 0.8561736941337585, epoch dist loss: 0.8455996587872505, epoch l2 loss: 1057.4037895202637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████▌                     | 10/20 [01:08<01:08,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 0.856886800378561, epoch dist loss: 0.8463826291263103, epoch l2 loss: 1050.4173851013184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|███████████████████████▋                   | 11/20 [01:14<01:01,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 0.8547359146177769, epoch dist loss: 0.8442382998764515, epoch l2 loss: 1049.761619567871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████▊                 | 12/20 [01:21<00:54,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 0.8513879887759686, epoch dist loss: 0.8407865837216377, epoch l2 loss: 1060.1399192810059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|███████████████████████████▉               | 13/20 [01:28<00:47,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 0.8575199022889137, epoch dist loss: 0.8468969725072384, epoch l2 loss: 1062.2933883666992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████             | 14/20 [01:35<00:40,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 0.85678531229496, epoch dist loss: 0.8462473042309284, epoch l2 loss: 1053.8017539978027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|████████████████████████████████▎          | 15/20 [01:41<00:33,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 0.8590172044932842, epoch dist loss: 0.8484474942088127, epoch l2 loss: 1056.9708099365234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████▍        | 16/20 [01:48<00:27,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 0.8589080162346363, epoch dist loss: 0.8482612818479538, epoch l2 loss: 1064.6739807128906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████████████████████████████████▌      | 17/20 [01:55<00:20,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 0.84994837641716, epoch dist loss: 0.8394412696361542, epoch l2 loss: 1050.7105865478516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|██████████████████████████████████████▋    | 18/20 [02:02<00:13,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 0.8500624038279057, epoch dist loss: 0.8393923006951809, epoch l2 loss: 1067.0100288391113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|████████████████████████████████████████▊  | 19/20 [02:09<00:06,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 0.8535559065639973, epoch dist loss: 0.8429470099508762, epoch l2 loss: 1060.8890380859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [02:15<00:00,  6.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for ADAR:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSVDD pred w/o causal: 0.0037735849056603765\n",
      "GT CR w/o causal: 0.0\n",
      "Delta x Avg: 55.56161129621147\n",
      "Ab GT Avg w/o causal: nan\n",
      "--------------------\n",
      "No GT results!\n",
      "--------------------\n",
      "DeepSVDD pred w VACA: 0.9886792452830189\n",
      "GT CR w VACA: 1.0\n",
      "GT x Avg w VACA: 42.313312013968854\n",
      "Ab GT Avg w VACA: 42.313312013968854\n",
      "--------------------------------------------------\n",
      "Training ADCAR:\n",
      "Epoch loss: 0.021078035584650934, epoch dist loss: 0.021053742617368698, epoch l2 loss: 2.429282918572426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|██▏                                         | 1/20 [01:15<23:46, 75.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02034749463200569\n",
      "Epoch loss: 0.021392769645899534, epoch dist loss: 0.02136146544944495, epoch l2 loss: 3.1303925216197968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████▍                                       | 2/20 [02:30<22:32, 75.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.024730945006012917\n",
      "Epoch loss: 0.02217093075159937, epoch dist loss: 0.02213274675887078, epoch l2 loss: 3.818399131298065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|██████▌                                     | 3/20 [03:45<21:17, 75.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027088429778814316\n",
      "Epoch loss: 0.021323708235286176, epoch dist loss: 0.021285189664922655, epoch l2 loss: 3.851875379681587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████▊                                   | 4/20 [05:00<20:03, 75.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026778526604175568\n",
      "Epoch loss: 0.021828505326993763, epoch dist loss: 0.0217821947298944, epoch l2 loss: 4.63104635477066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|███████████                                 | 5/20 [06:15<18:48, 75.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027884507551789284\n",
      "Epoch loss: 0.021700008190236986, epoch dist loss: 0.021652616444043815, epoch l2 loss: 4.739180579781532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|█████████████▏                              | 6/20 [07:31<17:32, 75.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03056384064257145\n",
      "Epoch loss: 0.021254812250845134, epoch dist loss: 0.021202044212259352, epoch l2 loss: 5.276795864105225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███████████████▍                            | 7/20 [08:46<16:17, 75.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.028145477175712585\n",
      "Epoch loss: 0.02139567513950169, epoch dist loss: 0.02133153355680406, epoch l2 loss: 6.414144396781921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████▌                          | 8/20 [10:01<15:02, 75.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.028622258454561234\n",
      "Epoch loss: 0.021148216677829623, epoch dist loss: 0.02107672148849815, epoch l2 loss: 7.149532049894333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|███████████████████▊                        | 9/20 [11:16<13:46, 75.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027573393657803535\n",
      "Epoch loss: 0.020742561318911612, epoch dist loss: 0.020668826182372868, epoch l2 loss: 7.373513370752335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████▌                     | 10/20 [12:31<12:31, 75.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02577989734709263\n",
      "Epoch loss: 0.021705506020225585, epoch dist loss: 0.021615659585222602, epoch l2 loss: 8.984629034996033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|███████████████████████▋                   | 11/20 [13:47<11:16, 75.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.023641124367713928\n",
      "Epoch loss: 0.021162951597943902, epoch dist loss: 0.021055362885817885, epoch l2 loss: 10.75887781381607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████▊                 | 12/20 [15:02<10:01, 75.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.024047093465924263\n",
      "Epoch loss: 0.02172527986112982, epoch dist loss: 0.021596815320663154, epoch l2 loss: 12.846430957317352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|███████████████████████████▉               | 13/20 [16:17<08:46, 75.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027905238792300224\n",
      "Epoch loss: 0.02181307110004127, epoch dist loss: 0.021665248088538647, epoch l2 loss: 14.782304525375366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████             | 14/20 [17:32<07:31, 75.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027297494933009148\n",
      "Epoch loss: 0.020635001710616052, epoch dist loss: 0.020470254472456872, epoch l2 loss: 16.474709689617157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|████████████████████████████████▎          | 15/20 [18:47<06:16, 75.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.024718033149838448\n",
      "Epoch loss: 0.018789017922244966, epoch dist loss: 0.018597430898807943, epoch l2 loss: 19.158707916736603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████▍        | 16/20 [20:03<05:00, 75.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.020405279472470284\n",
      "Epoch loss: 0.01724953658413142, epoch dist loss: 0.017068844637833536, epoch l2 loss: 18.069227159023285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████████████████████████████████▌      | 17/20 [21:18<03:45, 75.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01654723286628723\n",
      "Epoch loss: 0.01769055239856243, epoch dist loss: 0.01754197635455057, epoch l2 loss: 14.857591390609741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|██████████████████████████████████████▋    | 18/20 [22:33<02:30, 75.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01737377792596817\n",
      "Epoch loss: 0.017392388661392033, epoch dist loss: 0.01727146387565881, epoch l2 loss: 12.092471301555634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|████████████████████████████████████████▊  | 19/20 [23:48<01:15, 75.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019672906026244164\n",
      "Epoch loss: 0.018165216431953013, epoch dist loss: 0.01807645382359624, epoch l2 loss: 8.876262813806534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [25:03<00:00, 75.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02414647303521633\n",
      "Results for ADCAR:\n",
      "0.07960183266550303\n",
      "VACA results:\n",
      "DeepSVDD pred: 1.0\n",
      "GT CR: 1.0\n",
      "Delta x Avg Real: 5.411592483520508\n",
      "Ab GT Avg Real: 5.411592483520508\n",
      "Delta x Avg Org: 29.30277453780492\n",
      "Ab GT Avg Org: 29.30277453780492\n",
      "--------------------\n",
      "GT results:\n",
      "No GT results!\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=__doc__)\n",
    "parser.add_argument('--dataset_file', default='_params/dataset_donors_all.yaml', type=str,\n",
    "                    help='path to configuration file for the dataset')\n",
    "parser.add_argument('--model_file', default='_params/model_vaca_donors.yaml', type=str,\n",
    "                    help='path to configuration file for the dataset')\n",
    "parser.add_argument('--trainer_file', default='_params/trainer.yaml', type=str,\n",
    "                    help='path to configuration file for the training')\n",
    "parser.add_argument('--yaml_file', default='', type=str, help='path to trained model configuration')\n",
    "parser.add_argument('-d', '--dataset_dict', action=argtools.StoreDictKeyPair, metavar=\"KEY1=VAL1,KEY2=VAL2...\",\n",
    "                    help='manually define dataset configurations as string: KEY1=VALUE1+KEY2=VALUE2+...')\n",
    "parser.add_argument('-m', '--model_dict', action=argtools.StoreDictKeyPair, metavar=\"KEY1=VAL1,KEY2=VAL2...\",\n",
    "                    help='manually define model configurations as string: KEY1=VALUE1+KEY2=VALUE2+...')\n",
    "parser.add_argument('-o', '--optim_dict', action=argtools.StoreDictKeyPair, metavar=\"KEY1=VAL1,KEY2=VAL2...\",\n",
    "                    help='manually define optimizer configurations as string: KEY1=VALUE1+KEY2=VALUE2+...')\n",
    "parser.add_argument('-t', '--trainer_dict', action=argtools.StoreDictKeyPair, metavar=\"KEY1=VAL1,KEY2=VAL2...\",\n",
    "                    help='manually define trainer configurations as string: KEY1=VALUE1+KEY2=VALUE2+...')\n",
    "parser.add_argument('-s', '--seed', default=0, type=int, help='set random seed, default: random')\n",
    "parser.add_argument('-r', '--root_dir', default='', type=str, help='directory for storing results')\n",
    "parser.add_argument('--data_dir', default='', type=str, help='data directory')\n",
    "\n",
    "parser.add_argument('-i', '--is_training', default=0, type=int,\n",
    "                    help='run with training (1) or without training (0)')\n",
    "# parser.add_argument('-f', '--eval_fair', default=True, action=\"store_true\",\n",
    "#                     help='run code with counterfactual fairness experiment (only for German dataset), default: False')\n",
    "parser.add_argument('--show_results', default=0, action=\"store_true\",\n",
    "                    help='run with evaluation (1) or without(0), default: 1')\n",
    "\n",
    "parser.add_argument('--plots', default=1, type=int, help='run code with plotting (1) or without (0), default: 0')\n",
    "\n",
    "# DeepSVDD\n",
    "parser.add_argument('--training_size', default=10000, type=int, help='training size')\n",
    "parser.add_argument('--train_deepsvdd', default=0, type=int, help='train (1) or load(0) deepsvdd')\n",
    "\n",
    "parser.add_argument('--max_epoch_deepsvdd', default=1000, type=int, help='max epoch for training deepsvdd')\n",
    "parser.add_argument('--batch_size_deepsvdd', default=1024, type=int, help='batch size for training deepsvdd')\n",
    "parser.add_argument('--out_dim_deepsvdd', default=32, type=int, help='output dim for deepsvdd')\n",
    "parser.add_argument('--nu_deepsvdd', default=0.005, type=float, help='quantile for deepsvdd')\n",
    "\n",
    "# ADCAR\n",
    "parser.add_argument('--train_ADCAR', default=1, type=int, help='train (1) or load(0) ADCAR')\n",
    "parser.add_argument('--train_ADAR', default=1, type=int, help='train (1) or load(0) ADAR')\n",
    "parser.add_argument('--cost_function', default=1, type=int, help='using cost function')\n",
    "parser.add_argument('--l2_alpha', default=1e-5, type=float, help='Weight for the l2 loss')\n",
    "parser.add_argument('--device', default='cuda:0', type=str, help='Device to use')\n",
    "parser.add_argument('--max_epoch_ADCAR', default=20, type=int, help='max epoch for training ADCAR')\n",
    "parser.add_argument('--batch_size_ADCAR', default=128, type=int, help='batch size for training ADCAR')\n",
    "parser.add_argument('--learning_rate_ADCAR', default=1e-4, type=float, help='Learning rate for ADCAR')\n",
    "\n",
    "parser.add_argument('--r_ratio', default=0.0, type=float, help='R ratio for flap samples')\n",
    "\n",
    "\n",
    "args = parser.parse_args('')\n",
    "\n",
    "# %%\n",
    "if args.yaml_file == '':\n",
    "    cfg = argtools.parse_args(args.dataset_file)\n",
    "    cfg.update(argtools.parse_args(args.model_file))\n",
    "    cfg.update(argtools.parse_args(args.trainer_file))\n",
    "else:\n",
    "    cfg = argtools.parse_args(args.yaml_file)\n",
    "if len(args.root_dir) > 0:  cfg['root_dir'] = args.root_dir\n",
    "if int(args.seed) >= 0:\n",
    "    cfg['seed'] = int(args.seed)\n",
    "\n",
    "\n",
    "# %%\n",
    "pl.seed_everything(cfg['seed'])\n",
    "utils.set_seed(cfg['seed'])\n",
    "\n",
    "if args.dataset_dict is not None: cfg['dataset']['params2'].update(args.dataset_dict)\n",
    "if args.model_dict is not None: cfg['model']['params'].update(args.model_dict)\n",
    "if args.optim_dict is not None: cfg['optimizer']['params'].update(args.optim_dict)\n",
    "if args.trainer_dict is not None: cfg['trainer'].update(args.trainer_dict)\n",
    "\n",
    "if isinstance(cfg['trainer']['gpus'], int):\n",
    "    cfg['trainer']['auto_select_gpus'] = False\n",
    "    cfg['trainer']['gpus'] = -1\n",
    "\n",
    "cfg['dataset']['params'] = cfg['dataset']['params1'].copy()\n",
    "cfg['dataset']['params'].update(cfg['dataset']['params2'])\n",
    "\n",
    "if len(args.data_dir) > 0:\n",
    "    cfg['dataset']['params']['data_dir'] = args.data_dir\n",
    "\n",
    "print(args.dataset_dict)\n",
    "print(cfg['dataset']['params'])\n",
    "print(cfg['model']['params'])\n",
    "\n",
    "# %% Load dataset\n",
    "\n",
    "data_module = None\n",
    "\n",
    "if cfg['dataset']['name'] in Cte.DATASET_LIST:\n",
    "    from data_modules.het_scm import HeterogeneousSCMDataModule\n",
    "\n",
    "    dataset_params = cfg['dataset']['params'].copy()\n",
    "    dataset_params['dataset_name'] = cfg['dataset']['name']\n",
    "    dataset_params['num_samples_tr'] = args.training_size\n",
    "\n",
    "    data_module = HeterogeneousSCMDataModule(**dataset_params)\n",
    "\n",
    "    data_module.prepare_data()\n",
    "\n",
    "assert data_module is not None, cfg['dataset']\n",
    "\n",
    "# %% Load model\n",
    "model_vaca = None\n",
    "model_params = cfg['model']['params'].copy()\n",
    "# VACA\n",
    "if cfg['model']['name'] == Cte.VACA:\n",
    "    from models.vaca.vaca import VACA\n",
    "\n",
    "    model_params['is_heterogeneous'] = data_module.is_heterogeneous\n",
    "    model_params['likelihood_x'] = data_module.likelihood_list\n",
    "\n",
    "    model_params['deg'] = data_module.get_deg(indegree=True)\n",
    "    model_params['num_nodes'] = data_module.num_nodes\n",
    "    model_params['edge_dim'] = data_module.edge_dimension\n",
    "    model_params['scaler'] = data_module.scaler\n",
    "\n",
    "    model_vaca = VACA(**model_params)\n",
    "    model_vaca.set_random_train_sampler(data_module.get_random_train_sampler())\n",
    "# VACA with PIWAE\n",
    "elif cfg['model']['name'] == Cte.VACA_PIWAE:\n",
    "    from models.vaca.vaca_piwae import VACA_PIWAE\n",
    "\n",
    "    model_params['is_heterogeneous'] = data_module.is_heterogeneous\n",
    "\n",
    "    model_params['likelihood_x'] = data_module.likelihood_list\n",
    "\n",
    "    model_params['deg'] = data_module.get_deg(indegree=True)\n",
    "    model_params['num_nodes'] = data_module.num_nodes\n",
    "    model_params['edge_dim'] = data_module.edge_dimension\n",
    "    model_params['scaler'] = data_module.scaler\n",
    "\n",
    "    model_vaca = VACA_PIWAE(**model_params)\n",
    "    model_vaca.set_random_train_sampler(data_module.get_random_train_sampler())\n",
    "\n",
    "\n",
    "\n",
    "# MultiCVAE\n",
    "elif cfg['model']['name'] == Cte.MCVAE:\n",
    "    from models.multicvae.multicvae import MCVAE\n",
    "\n",
    "    model_params['likelihood_x'] = data_module.likelihood_list\n",
    "\n",
    "    model_params['topological_node_dims'] = data_module.train_dataset.get_node_columns_in_X()\n",
    "    model_params['topological_parents'] = data_module.topological_parents\n",
    "    model_params['scaler'] = data_module.scaler\n",
    "    model_params['num_epochs_per_nodes'] = int(\n",
    "        np.floor((cfg['trainer']['max_epochs'] / len(data_module.topological_nodes))))\n",
    "    model_vaca = MCVAE(**model_params)\n",
    "    model_vaca.set_random_train_sampler(data_module.get_random_train_sampler())\n",
    "    cfg['early_stopping'] = False\n",
    "\n",
    "# CAREFL\n",
    "elif cfg['model']['name'] == Cte.CARELF:\n",
    "    from models.carefl.carefl import CAREFL\n",
    "\n",
    "    model_params['node_per_dimension_list'] = data_module.train_dataset.node_per_dimension_list\n",
    "    model_params['scaler'] = data_module.scaler\n",
    "    model_vaca = CAREFL(**model_params)\n",
    "assert model_vaca is not None\n",
    "\n",
    "utools.enablePrint()\n",
    "\n",
    "print(model_vaca.model)\n",
    "model_vaca.summarize()\n",
    "model_vaca.set_optim_params(optim_params=cfg['optimizer'],\n",
    "                            sched_params=cfg['scheduler'])\n",
    "\n",
    "# %% Evaluator\n",
    "\n",
    "evaluator = None\n",
    "\n",
    "if cfg['dataset']['name'] in Cte.DATASET_LIST:\n",
    "    from models._evaluator import MyEvaluator\n",
    "\n",
    "    evaluator = MyEvaluator(model=model_vaca,\n",
    "                            intervention_list=data_module.train_dataset.get_intervention_list(),\n",
    "                            scaler=data_module.scaler\n",
    "                            )\n",
    "\n",
    "assert evaluator is not None\n",
    "\n",
    "model_vaca.set_my_evaluator(evaluator=evaluator)\n",
    "\n",
    "# %% Prepare training\n",
    "if args.yaml_file == '':\n",
    "    if (cfg['dataset']['name'] in [Cte.GERMAN]) and (cfg['dataset']['params3']['train_kfold'] == True):\n",
    "        save_dir = argtools.mkdir(os.path.join(cfg['root_dir'],\n",
    "                                               argtools.get_experiment_folder(cfg),\n",
    "                                               str(cfg['seed']), str(cfg['dataset']['params3']['kfold_idx'])))\n",
    "    else:\n",
    "        save_dir = argtools.mkdir(os.path.join(cfg['root_dir'],\n",
    "                                               argtools.get_experiment_folder(cfg),\n",
    "                                               str(cfg['seed'])))\n",
    "else:\n",
    "    save_dir = os.path.join(*args.yaml_file.split('/')[:-1])\n",
    "print(f'Save dir: {save_dir}')\n",
    "# trainer = pl.Trainer(**cfg['model'])\n",
    "logger = TensorBoardLogger(save_dir=save_dir, name='logs', default_hp_metric=False)\n",
    "out = logger.log_hyperparams(argtools.flatten_cfg(cfg))\n",
    "\n",
    "save_dir_ckpt = argtools.mkdir(os.path.join(save_dir, 'ckpt'))\n",
    "ckpt_file = argtools.newest(save_dir_ckpt)\n",
    "callbacks = []\n",
    "if args.is_training == 1:\n",
    "\n",
    "    checkpoint = ModelCheckpoint(period=1,\n",
    "                                 monitor=model_vaca.monitor(),\n",
    "                                 mode=model_vaca.monitor_mode(),\n",
    "                                 save_top_k=1,\n",
    "                                 save_last=True,\n",
    "                                 filename='checkpoint-{epoch:02d}',\n",
    "                                 dirpath=save_dir_ckpt)\n",
    "\n",
    "    callbacks = [checkpoint]\n",
    "\n",
    "    if cfg['early_stopping']:\n",
    "        early_stopping = EarlyStopping(model_vaca.monitor(), mode=model_vaca.monitor_mode(), min_delta=0.0,\n",
    "                                       patience=50)\n",
    "        callbacks.append(early_stopping)\n",
    "\n",
    "    if ckpt_file is not None:\n",
    "        print(f'Loading model training: {ckpt_file}')\n",
    "        trainer = pl.Trainer(logger=logger, callbacks=callbacks, resume_from_checkpoint=ckpt_file,\n",
    "                             **cfg['trainer'])\n",
    "    else:\n",
    "\n",
    "        trainer = pl.Trainer(logger=logger, callbacks=callbacks, **cfg['trainer'])\n",
    "\n",
    "    # %% Train\n",
    "\n",
    "    trainer.fit(model_vaca, data_module)\n",
    "    # save_yaml(model.get_arguments(), file_path=os.path.join(save_dir, 'hparams_model.yaml'))\n",
    "    argtools.save_yaml(cfg, file_path=os.path.join(save_dir, 'hparams_full.yaml'))\n",
    "    # %% Testing\n",
    "\n",
    "else:\n",
    "    # %% Testing\n",
    "    trainer = pl.Trainer()\n",
    "    print('\\nLoading from: ')\n",
    "    print(ckpt_file)\n",
    "\n",
    "    model_vaca = model_vaca.load_from_checkpoint(ckpt_file, **model_params)\n",
    "    evaluator.set_model(model_vaca)\n",
    "    model_vaca.set_my_evaluator(evaluator=evaluator)\n",
    "\n",
    "    if cfg['model']['name'] in [Cte.VACA_PIWAE, Cte.VACA, Cte.MCVAE]:\n",
    "        model_vaca.set_random_train_sampler(data_module.get_random_train_sampler())\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model_vaca.parameters())\n",
    "params = int(sum([np.prod(p.size()) for p in model_parameters]))\n",
    "\n",
    "print(f'Model parameters: {params}')\n",
    "model_vaca.eval()\n",
    "model_vaca.freeze()  # IMPORTANT\n",
    "\n",
    "if args.show_results:\n",
    "    output_valid = model_vaca.evaluate(dataloader=data_module.val_dataloader(),\n",
    "                                       name='valid',\n",
    "                                       save_dir=save_dir,\n",
    "                                       plots=False)\n",
    "    output_test = model_vaca.evaluate(dataloader=data_module.test_dataloader(),\n",
    "                                      name='test',\n",
    "                                      save_dir=save_dir,\n",
    "                                      plots=args.plots)\n",
    "    output_valid.update(output_test)\n",
    "\n",
    "    output_valid.update(argtools.flatten_cfg(cfg))\n",
    "    output_valid.update({'ckpt_file': ckpt_file,\n",
    "                         'num_parameters': params})\n",
    "\n",
    "    with open(os.path.join(save_dir, 'output.json'), 'w') as f:\n",
    "        json.dump(output_valid, f)\n",
    "    print(f'Experiment folder: {save_dir}')\n",
    "    \n",
    "thres_n, thres_ab, df_train, df_valid, df_test = utils.split_dataset(data_module, name=cfg['dataset']['name'], \\\n",
    "                                                                     training_size=args.training_size,\n",
    "                                                                     seed=args.seed)\n",
    "\n",
    "if cfg['dataset']['name'] == 'loan':\n",
    "    input_dim = data_module.train_dataset.X0.shape[-1]\n",
    "elif cfg['dataset']['name'] == 'adult':\n",
    "    input_dim = data_module.train_dataset.X0.shape[-1] - 4\n",
    "elif cfg['dataset']['name'] == 'donors':\n",
    "    input_dim = data_module.train_dataset.X0.shape[-1] - 1\n",
    "else:\n",
    "    NotImplementedError\n",
    "\n",
    "model_deepsvdd = deepsvdd.DeepSVDD(input_dim=input_dim, out_dim=args.out_dim_deepsvdd,\n",
    "                                   batch_size=args.batch_size_deepsvdd, nu=args.nu_deepsvdd,\n",
    "                                   max_epoch=args.max_epoch_deepsvdd, data=data_module.dataset_name,\n",
    "                                   device=args.device)\n",
    "\n",
    "if cfg['dataset']['name'] == 'loan':\n",
    "    train_X = data_module.scaler.transform(data_module.train_dataset.X0)\n",
    "    valid_X = data_module.scaler.transform(data_module.valid_dataset.X0)\n",
    "    test_X = data_module.scaler.transform(data_module.test_dataset.X0)\n",
    "elif cfg['dataset']['name'] == 'adult':\n",
    "    train_X = data_module.scaler.transform(data_module.train_dataset.X0)[:, :-4]\n",
    "    valid_X = data_module.scaler.transform(data_module.valid_dataset.X0)[:, :-4]\n",
    "    test_X = data_module.scaler.transform(data_module.test_dataset.X0)[:, :-4]\n",
    "elif cfg['dataset']['name'] == 'donors':\n",
    "    train_X = data_module.scaler.transform(data_module.train_dataset.X0)[:, :-1]\n",
    "    valid_X = data_module.scaler.transform(data_module.valid_dataset.X0)[:, :-1]\n",
    "    test_X = data_module.scaler.transform(data_module.test_dataset.X0)[:, :-1]\n",
    "else:\n",
    "    NotImplementedError\n",
    "\n",
    "if args.train_deepsvdd:\n",
    "    print('Training DeepSVDD:')\n",
    "    model_deepsvdd.train_DeepSVDD(train_X, valid_X)\n",
    "\n",
    "print('Results for DeepSVDD:')\n",
    "model_deepsvdd.load_model()\n",
    "model_deepsvdd.get_R(train_X)\n",
    "if cfg['dataset']['name'] == 'donors':\n",
    "    lst_dist, lst_pred = model_deepsvdd.predict(test_X, label=df_test['is_exciting'].values, result=1)\n",
    "else:\n",
    "    lst_dist, lst_pred = model_deepsvdd.predict(test_X, label=df_test['label'].values, result=1)\n",
    "\n",
    "if cfg['dataset']['name'] == 'loan':\n",
    "    out_dim = 6\n",
    "elif cfg['dataset']['name'] == 'adult':\n",
    "    out_dim = 3\n",
    "elif cfg['dataset']['name'] == 'donors':\n",
    "    out_dim = 3\n",
    "else:\n",
    "    NotImplementedError\n",
    "\n",
    "\n",
    "model_adar = adar.ADAR(input_dim, out_dim, model_deepsvdd, model_vaca, data_module,\n",
    "                       alpha=args.l2_alpha, batch_size=args.batch_size_ADCAR, max_epoch=args.max_epoch_ADCAR,\n",
    "                       device=args.device, data=cfg['dataset']['name'], cost_f=args.cost_function,\n",
    "                       R_ratio=args.r_ratio, lr=args.learning_rate_ADCAR)\n",
    "                       # device=args.device, data=cfg['dataset']['name'], cost_f=args.cost_function, R_ratio=i)\n",
    "x_train, u_train, x_valid, u_valid, x_test, u_test, df = utils.prepare_adcar_training_data(df_test, lst_pred, data_module,\n",
    "                                                                                           cfg['dataset']['name'])\n",
    "if args.train_ADAR:\n",
    "    print('Training ADAR:')\n",
    "    model_adar.train_ADAR(x_train, u_train, x_valid, u_valid)\n",
    "print('Results for ADAR:')\n",
    "# model_adar.predict(x_train, u_train)\n",
    "model_adar.predict(x_test, u_test, thres_n=thres_n)\n",
    "\n",
    "print('-'*50)\n",
    "model_adcar = adcar.ADCAR(input_dim, out_dim, model_deepsvdd, model_vaca, data_module,\n",
    "                       alpha=args.l2_alpha, batch_size=args.batch_size_ADCAR, max_epoch=args.max_epoch_ADCAR,\n",
    "                       device=args.device, data=cfg['dataset']['name'], cost_f=args.cost_function, R_ratio=args.r_ratio)\n",
    "                       # device=args.device, data=cfg['dataset']['name'], cost_f=args.cost_function, R_ratio=i)\n",
    "\n",
    "if args.train_ADCAR:\n",
    "    print('Training ADCAR:')\n",
    "    model_adcar.train_ADCAR(x_train, u_train, x_valid, u_valid)\n",
    "print('Results for ADCAR:')\n",
    "# model_adcar.predict(x_train, u_train)\n",
    "model_adcar.predict(x_test, u_test, thres_n=thres_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADCAR\n",
    "parser.add_argument('--train_ADCAR', default=1, type=int, help='train (1) or load(0) ADCAR')\n",
    "parser.add_argument('--train_ADAR', default=1, type=int, help='train (1) or load(0) ADAR')\n",
    "parser.add_argument('--cost_function', default=1, type=int, help='using cost function')\n",
    "parser.add_argument('--l2_alpha', default=1e-5, type=float, help='Weight for the l2 loss')\n",
    "parser.add_argument('--device', default='cuda:0', type=str, help='Device to use')\n",
    "parser.add_argument('--max_epoch_ADCAR', default=20, type=int, help='max epoch for training ADCAR')\n",
    "parser.add_argument('--batch_size_ADCAR', default=128, type=int, help='batch size for training ADCAR')\n",
    "parser.add_argument('--learning_rate_ADCAR', default=1e-4, type=float, help='Learning rate for ADCAR')\n",
    "\n",
    "parser.add_argument('--r_ratio', default=0.0, type=float, help='R ratio for flap samples')\n",
    "index = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>at_least_1_teacher_referred_donor</th>\n",
       "      <th>fully_funded</th>\n",
       "      <th>at_least_1_green_donation</th>\n",
       "      <th>great_chat</th>\n",
       "      <th>three_or_more_non_teacher_referred_donors</th>\n",
       "      <th>one_non_teacher_referred_donor_giving_100_plus</th>\n",
       "      <th>donation_from_thoughtful_donor</th>\n",
       "      <th>great_messages_proportion</th>\n",
       "      <th>teacher_referred_count</th>\n",
       "      <th>non_teacher_referred_count</th>\n",
       "      <th>is_exciting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   at_least_1_teacher_referred_donor  fully_funded  at_least_1_green_donation  \\\n",
       "0                                0.0           1.0                        0.0   \n",
       "1                                0.0           1.0                        0.0   \n",
       "2                                1.0           1.0                        1.0   \n",
       "\n",
       "   great_chat  three_or_more_non_teacher_referred_donors  \\\n",
       "0         0.0                                        0.0   \n",
       "1         0.0                                        0.0   \n",
       "2         1.0                                        0.0   \n",
       "\n",
       "   one_non_teacher_referred_donor_giving_100_plus  \\\n",
       "0                                             1.0   \n",
       "1                                             1.0   \n",
       "2                                             1.0   \n",
       "\n",
       "   donation_from_thoughtful_donor  great_messages_proportion  \\\n",
       "0                             0.0                       50.0   \n",
       "1                             0.0                       58.0   \n",
       "2                             0.0                       72.0   \n",
       "\n",
       "   teacher_referred_count  non_teacher_referred_count  is_exciting  \n",
       "0                     0.0                         2.0          1.0  \n",
       "1                    19.0                       -42.0          1.0  \n",
       "2                    19.0                         0.0          0.0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_theta_adar, _,_, df_adar = model_adar.get_result(x_test[index], u_test[index])\n",
    "x_theta_adcar, _,_, df_adcar = model_adcar.get_result(x_test[index], u_test[index])\n",
    "index += 1\n",
    "df_adar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8.147773,  18.863539, -43.64193 ], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_theta_adar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>at_least_1_teacher_referred_donor</th>\n",
       "      <th>fully_funded</th>\n",
       "      <th>at_least_1_green_donation</th>\n",
       "      <th>great_chat</th>\n",
       "      <th>three_or_more_non_teacher_referred_donors</th>\n",
       "      <th>one_non_teacher_referred_donor_giving_100_plus</th>\n",
       "      <th>donation_from_thoughtful_donor</th>\n",
       "      <th>great_messages_proportion</th>\n",
       "      <th>teacher_referred_count</th>\n",
       "      <th>non_teacher_referred_count</th>\n",
       "      <th>is_exciting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   at_least_1_teacher_referred_donor  fully_funded  at_least_1_green_donation  \\\n",
       "0                                0.0           1.0                        0.0   \n",
       "1                                1.0           1.0                        1.0   \n",
       "\n",
       "   great_chat  three_or_more_non_teacher_referred_donors  \\\n",
       "0         0.0                                        0.0   \n",
       "1         1.0                                        0.0   \n",
       "\n",
       "   one_non_teacher_referred_donor_giving_100_plus  \\\n",
       "0                                             1.0   \n",
       "1                                             1.0   \n",
       "\n",
       "   donation_from_thoughtful_donor  great_messages_proportion  \\\n",
       "0                             0.0                       50.0   \n",
       "1                             0.0                       68.0   \n",
       "\n",
       "   teacher_referred_count  non_teacher_referred_count  is_exciting  \n",
       "0                     0.0                         2.0          1.0  \n",
       "1                     1.0                         2.0          0.0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adcar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.649946 ,  1.4677929, -0.3697624], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_theta_adcar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}